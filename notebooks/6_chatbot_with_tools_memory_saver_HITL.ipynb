{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e518ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is example of Human in the loop, before executing decision, will ask for user confirmation\n",
    "# not working some issue in getting user input and process further\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "#llm creation\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "#llm.invoke(\"who is the king in then north?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt, Command\n",
    "@tool\n",
    "def get_stock_price(stok: str)->str:\n",
    "    ''' Return the current stock price of the given stock\n",
    "    param stock: stock name\n",
    "    return current price of the stock\n",
    "    '''\n",
    "    return {\n",
    "        \"HCL\": 1280,\n",
    "        \"TCS\": 3000,\n",
    "        \"IDFC\": 200\n",
    "    }.get(stok, 0)\n",
    "    \n",
    "@tool\n",
    "def buy_stock_price(stock: str, quantity: int, total_price: float) -> str:\n",
    "    '''\n",
    "    Buy stock given the stock and quantity.\n",
    "    Will ask user for approval.\n",
    "    '''\n",
    "    decision = interrupt(f\"Approve buying {quantity} of {stock} for ₹{total_price}? (yes/no)\")\n",
    "    if decision.lower() == 'yes':\n",
    "        return f\"✅ Purchased {quantity} of {stock}.\"\n",
    "    else:\n",
    "        return \"❌ Purchase cancelled.\"\n",
    "    \n",
    "tool_list = [get_stock_price,buy_stock_price]\n",
    "\n",
    "#bind with llm tools\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "\n",
    "#llm_with_tools.invoke(\"what is the price of HCL stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "#state of the graph\n",
    "class State(TypedDict):\n",
    "\tmessages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State) -> State:\n",
    "    # Preserve message history by appending the new response to the existing messages\n",
    "    response = { \"messages\" : [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "    return response\n",
    "\n",
    "#graph configuation\n",
    "memory = MemorySaver()\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chat_node\", chatbot)\n",
    "builder.add_node(\"tools\", ToolNode(tool_list))\n",
    "builder.add_edge(START, \"chat_node\")\n",
    "builder.add_conditional_edges('chat_node', tools_condition)\n",
    "builder.add_edge(\"tools\", \"chat_node\")\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07272b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "#display the created graph as an image\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from pprint import pprint\n",
    "# session id configuration we can define session id for our each thread\n",
    "config = {'configurable': {'thread_id': 123}}\n",
    "while True:\n",
    "    input_msg = input(\"You: \")\n",
    "    if input_msg in {\"quit\", \"exit\"}:\n",
    "        break\n",
    "    graph_state = graph.invoke({\n",
    "        \"messages\": HumanMessage(content=input_msg)\n",
    "    },config)\n",
    "    last_msg = graph_state[\"messages\"][-1]\n",
    "    if graph_state.get(\"__interrupt__\") :\n",
    "        print('waiting for user input')\n",
    "        print(last_msg)\n",
    "        user_answer=  input(\"approve yes/no\")\n",
    "        response = graph.invoke(Command(resume=user_answer),config)\n",
    "        \n",
    "    pprint(last_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933778b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-workflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
